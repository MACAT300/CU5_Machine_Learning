{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Case Study: Butterfly Species Classification\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "In this case study, you will build a Convolutional Neural Network (CNN) to classify images of butterflies and moths into **100 different species**. This is a comprehensive deep learning project that covers:\n",
    "\n",
    "- Data loading and preprocessing\n",
    "- Exploratory data analysis\n",
    "- Building CNN architectures from scratch\n",
    "- Transfer learning with pre-trained models\n",
    "- Model evaluation and visualization\n",
    "- Hyperparameter tuning\n",
    "\n",
    "### Dataset Information\n",
    "\n",
    "- **Source**: [Kaggle - Butterfly Images (100 species)](https://www.kaggle.com/datasets/gpiosenka/butterfly-images40-species)\n",
    "- **Total Images**: 13,595\n",
    "- **Image Size**: 224 × 224 × 3 (RGB)\n",
    "- **Classes**: 100 butterfly and moth species\n",
    "- **Split**: \n",
    "  - Training: 12,594 images\n",
    "  - Validation: 500 images (5 per species)\n",
    "  - Test: 500 images (5 per species)\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By completing this case study, you will:\n",
    "1. Understand how to work with image datasets\n",
    "2. Build and train CNNs using TensorFlow/Keras\n",
    "3. Implement data augmentation techniques\n",
    "4. Compare different model architectures\n",
    "5. Apply transfer learning\n",
    "6. Evaluate model performance using various metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, MobileNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# Scikit-learn for metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Display settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Loading and Exploration\n",
    "\n",
    "### 2.1 Download the Dataset\n",
    "\n",
    "First, download the dataset from Kaggle. You'll need to:\n",
    "1. Install Kaggle API: `pip install kaggle`\n",
    "2. Set up your Kaggle API credentials\n",
    "3. Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run these lines to download the dataset\n",
    "# !pip install kaggle\n",
    "# !kaggle datasets download -d gpiosenka/butterfly-images40-species\n",
    "# !unzip butterfly-images40-species.zip -d butterfly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths - UPDATE THESE PATHS according to your setup\n",
    "BASE_DIR = Path('butterfly_data')  # Update this to your data directory\n",
    "TRAIN_DIR = BASE_DIR / 'train'\n",
    "VALID_DIR = BASE_DIR / 'valid'\n",
    "TEST_DIR = BASE_DIR / 'test'\n",
    "\n",
    "# Image parameters\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "IMG_CHANNELS = 3\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print(f\"Train directory exists: {TRAIN_DIR.exists()}\")\n",
    "print(f\"Valid directory exists: {VALID_DIR.exists()}\")\n",
    "print(f\"Test directory exists: {TEST_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Explore the Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count images in each set\n",
    "def count_images(directory):\n",
    "    \"\"\"Count total images and images per class in a directory.\"\"\"\n",
    "    total = 0\n",
    "    class_counts = {}\n",
    "    \n",
    "    for class_dir in sorted(directory.iterdir()):\n",
    "        if class_dir.is_dir():\n",
    "            num_images = len(list(class_dir.glob('*.jpg')))\n",
    "            class_counts[class_dir.name] = num_images\n",
    "            total += num_images\n",
    "    \n",
    "    return total, class_counts\n",
    "\n",
    "# Count images in each set\n",
    "train_total, train_counts = count_images(TRAIN_DIR)\n",
    "valid_total, valid_counts = count_images(VALID_DIR)\n",
    "test_total, test_counts = count_images(TEST_DIR)\n",
    "\n",
    "print(f\"Training images: {train_total}\")\n",
    "print(f\"Validation images: {valid_total}\")\n",
    "print(f\"Test images: {test_total}\")\n",
    "print(f\"\\nNumber of classes: {len(train_counts)}\")\n",
    "print(f\"\\nFirst 10 species: {list(train_counts.keys())[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_images(directory, num_samples=12, figsize=(15, 10)):\n",
    "    \"\"\"Plot random sample images from the dataset.\"\"\"\n",
    "    classes = sorted([d.name for d in directory.iterdir() if d.is_dir()])\n",
    "    selected_classes = np.random.choice(classes, min(num_samples, len(classes)), replace=False)\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 4, figsize=figsize)\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, class_name in enumerate(selected_classes):\n",
    "        class_dir = directory / class_name\n",
    "        images = list(class_dir.glob('*.jpg'))\n",
    "        \n",
    "        if images:\n",
    "            random_image = np.random.choice(images)\n",
    "            img = load_img(random_image, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "            \n",
    "            axes[idx].imshow(img)\n",
    "            axes[idx].set_title(class_name, fontsize=10)\n",
    "            axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Sample Butterfly Images', fontsize=16, y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "plot_sample_images(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Class Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "def plot_class_distribution(class_counts, title=\"Class Distribution\", top_n=20):\n",
    "    \"\"\"Plot class distribution as a bar chart.\"\"\"\n",
    "    df = pd.DataFrame(list(class_counts.items()), columns=['Class', 'Count'])\n",
    "    df = df.sort_values('Count', ascending=False).head(top_n)\n",
    "    \n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.bar(range(len(df)), df['Count'], color='steelblue')\n",
    "    plt.xlabel('Species', fontsize=12)\n",
    "    plt.ylabel('Number of Images', fontsize=12)\n",
    "    plt.title(f'{title} (Top {top_n})', fontsize=14)\n",
    "    plt.xticks(range(len(df)), df['Class'], rotation=90, ha='right', fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Mean images per class: {df['Count'].mean():.2f}\")\n",
    "    print(f\"Std images per class: {df['Count'].std():.2f}\")\n",
    "    print(f\"Min images per class: {df['Count'].min()}\")\n",
    "    print(f\"Max images per class: {df['Count'].max()}\")\n",
    "\n",
    "plot_class_distribution(train_counts, \"Training Set Class Distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Preprocessing and Augmentation\n",
    "\n",
    "### 3.1 Create Data Generators\n",
    "\n",
    "We'll use `ImageDataGenerator` for:\n",
    "1. **Normalization**: Scale pixel values to [0, 1]\n",
    "2. **Data Augmentation**: Create variations of training images to improve generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data generator WITH augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,              # Normalize pixel values to [0, 1]\n",
    "    rotation_range=20,           # Random rotation up to 20 degrees\n",
    "    width_shift_range=0.2,       # Random horizontal shift\n",
    "    height_shift_range=0.2,      # Random vertical shift\n",
    "    shear_range=0.2,             # Shear transformation\n",
    "    zoom_range=0.2,              # Random zoom\n",
    "    horizontal_flip=True,        # Random horizontal flip\n",
    "    fill_mode='nearest'          # Fill empty pixels after transformations\n",
    ")\n",
    "\n",
    "# Validation and test data generators WITHOUT augmentation (only rescaling)\n",
    "valid_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "validation_generator = valid_test_datagen.flow_from_directory(\n",
    "    VALID_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = valid_test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Get class labels\n",
    "class_labels = {v: k for k, v in train_generator.class_indices.items()}\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Training batches: {len(train_generator)}\")\n",
    "print(f\"Validation batches: {len(validation_generator)}\")\n",
    "print(f\"Test batches: {len(test_generator)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Visualize Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_augmentation(generator, num_images=5):\n",
    "    \"\"\"Visualize augmented versions of a single image.\"\"\"\n",
    "    # Get a batch of images\n",
    "    x_batch, y_batch = next(generator)\n",
    "    \n",
    "    # Take the first image\n",
    "    img = x_batch[0]\n",
    "    \n",
    "    # Create augmented versions\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(15, 3))\n",
    "    \n",
    "    axes[0].imshow(img)\n",
    "    axes[0].set_title('Original')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Generate augmented versions\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = img_array.reshape((1,) + img_array.shape)\n",
    "    \n",
    "    aug_iter = train_datagen.flow(img_array, batch_size=1)\n",
    "    \n",
    "    for i in range(1, num_images):\n",
    "        batch = next(aug_iter)\n",
    "        aug_img = batch[0]\n",
    "        axes[i].imshow(aug_img)\n",
    "        axes[i].set_title(f'Augmented {i}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_augmentation(train_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Building CNN Models\n",
    "\n",
    "We'll build three different models with increasing complexity:\n",
    "1. **Simple CNN**: Basic architecture for baseline\n",
    "2. **Deeper CNN**: More layers and complexity\n",
    "3. **Transfer Learning**: Using pre-trained models (VGG16, ResNet50, MobileNetV2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Model 1: Simple CNN (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_cnn(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), num_classes=num_classes):\n",
    "    \"\"\"\n",
    "    Create a simple CNN model with 3 convolutional blocks.\n",
    "    \n",
    "    Architecture:\n",
    "    - 3 Conv2D + MaxPooling blocks\n",
    "    - Flatten\n",
    "    - Dense layers with dropout\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        # First convolutional block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Second convolutional block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Third convolutional block\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Flatten and fully connected layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and display model\n",
    "simple_cnn = create_simple_cnn()\n",
    "simple_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Model 2: Deeper CNN with Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_deeper_cnn(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), num_classes=num_classes):\n",
    "    \"\"\"\n",
    "    Create a deeper CNN model with batch normalization.\n",
    "    \n",
    "    Architecture:\n",
    "    - 4 Conv2D blocks with BatchNormalization\n",
    "    - MaxPooling after each block\n",
    "    - Dropout for regularization\n",
    "    - Dense layers with dropout\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        # Block 1\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Block 2\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Block 3\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Block 4\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Fully connected layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "deeper_cnn = create_deeper_cnn()\n",
    "deeper_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Model 3: Transfer Learning with Pre-trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transfer_learning_model(base_model_name='MobileNetV2', \n",
    "                                   input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),\n",
    "                                   num_classes=num_classes,\n",
    "                                   trainable_layers=0):\n",
    "    \"\"\"\n",
    "    Create a transfer learning model using pre-trained architectures.\n",
    "    \n",
    "    Args:\n",
    "        base_model_name: 'VGG16', 'ResNet50', or 'MobileNetV2'\n",
    "        input_shape: Input image shape\n",
    "        num_classes: Number of output classes\n",
    "        trainable_layers: Number of top layers to make trainable (0 = freeze all)\n",
    "    \"\"\"\n",
    "    # Load pre-trained base model\n",
    "    if base_model_name == 'VGG16':\n",
    "        base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif base_model_name == 'ResNet50':\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif base_model_name == 'MobileNetV2':\n",
    "        base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown base model: {base_model_name}\")\n",
    "    \n",
    "    # Freeze base model layers\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # If trainable_layers > 0, unfreeze top layers\n",
    "    if trainable_layers > 0:\n",
    "        base_model.trainable = True\n",
    "        for layer in base_model.layers[:-trainable_layers]:\n",
    "            layer.trainable = False\n",
    "    \n",
    "    # Build the model\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create transfer learning model with MobileNetV2\n",
    "transfer_model = create_transfer_learning_model('MobileNetV2')\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Model Compilation and Training\n",
    "\n",
    "### 5.1 Define Training Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(model_name, patience=5):\n",
    "    \"\"\"\n",
    "    Create callbacks for training.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name for saving checkpoints\n",
    "        patience: Number of epochs to wait before early stopping\n",
    "    \"\"\"\n",
    "    callbacks = [\n",
    "        # Early stopping: stop if validation loss doesn't improve\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=patience,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Model checkpoint: save best model\n",
    "        ModelCheckpoint(\n",
    "            f'{model_name}_best.h5',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            mode='max',\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Reduce learning rate when plateauing\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Train the Simple CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "simple_cnn.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "EPOCHS = 30\n",
    "\n",
    "history_simple = simple_cnn.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=get_callbacks('simple_cnn', patience=5),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Train the Deeper CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "deeper_cnn.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history_deeper = deeper_cnn.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=get_callbacks('deeper_cnn', patience=5),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Train the Transfer Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "transfer_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),  # Lower learning rate for transfer learning\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history_transfer = transfer_model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=get_callbacks('transfer_model', patience=7),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Model Evaluation and Visualization\n",
    "\n",
    "### 6.1 Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, model_name):\n",
    "    \"\"\"\n",
    "    Plot training and validation accuracy/loss over epochs.\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    ax1.plot(history.history['accuracy'], label='Training Accuracy', marker='o')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='s')\n",
    "    ax1.set_xlabel('Epoch', fontsize=12)\n",
    "    ax1.set_ylabel('Accuracy', fontsize=12)\n",
    "    ax1.set_title(f'{model_name} - Accuracy', fontsize=14)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot loss\n",
    "    ax2.plot(history.history['loss'], label='Training Loss', marker='o')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Loss', marker='s')\n",
    "    ax2.set_xlabel('Epoch', fontsize=12)\n",
    "    ax2.set_ylabel('Loss', fontsize=12)\n",
    "    ax2.set_title(f'{model_name} - Loss', fontsize=14)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print final metrics\n",
    "    print(f\"\\n{model_name} - Final Metrics:\")\n",
    "    print(f\"Training Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "    print(f\"Validation Accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "    print(f\"Training Loss: {history.history['loss'][-1]:.4f}\")\n",
    "    print(f\"Validation Loss: {history.history['val_loss'][-1]:.4f}\")\n",
    "\n",
    "# Plot histories\n",
    "plot_training_history(history_simple, 'Simple CNN')\n",
    "plot_training_history(history_deeper, 'Deeper CNN')\n",
    "plot_training_history(history_transfer, 'Transfer Learning (MobileNetV2)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Compare All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(histories, model_names):\n",
    "    \"\"\"\n",
    "    Compare validation accuracy of all models on the same plot.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    for history, name in zip(histories, model_names):\n",
    "        plt.plot(history.history['val_accuracy'], label=name, marker='o', linewidth=2)\n",
    "    \n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('Validation Accuracy', fontsize=12)\n",
    "    plt.title('Model Comparison - Validation Accuracy', fontsize=14)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "compare_models(\n",
    "    [history_simple, history_deeper, history_transfer],\n",
    "    ['Simple CNN', 'Deeper CNN', 'Transfer Learning']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_generator, model_name):\n",
    "    \"\"\"\n",
    "    Evaluate model on test set and print metrics.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Evaluating {model_name} on Test Set\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Evaluate\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator, verbose=1)\n",
    "    \n",
    "    print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    \n",
    "    return test_accuracy, test_loss\n",
    "\n",
    "# Evaluate all models\n",
    "simple_test_acc, simple_test_loss = evaluate_model(simple_cnn, test_generator, 'Simple CNN')\n",
    "deeper_test_acc, deeper_test_loss = evaluate_model(deeper_cnn, test_generator, 'Deeper CNN')\n",
    "transfer_test_acc, transfer_test_loss = evaluate_model(transfer_model, test_generator, 'Transfer Learning')\n",
    "\n",
    "# Summary comparison\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Model':<30} {'Test Accuracy':<20} {'Test Loss':<20}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'Simple CNN':<30} {simple_test_acc:<20.4f} {simple_test_loss:<20.4f}\")\n",
    "print(f\"{'Deeper CNN':<30} {deeper_test_acc:<20.4f} {deeper_test_loss:<20.4f}\")\n",
    "print(f\"{'Transfer Learning':<30} {transfer_test_acc:<20.4f} {transfer_test_loss:<20.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Generate Predictions and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best performing model (likely transfer learning)\n",
    "best_model = transfer_model\n",
    "\n",
    "# Get predictions\n",
    "test_generator.reset()\n",
    "predictions = best_model.predict(test_generator, verbose=1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get true labels\n",
    "true_classes = test_generator.classes\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report (First 20 classes):\")\n",
    "print(\"=\"*80)\n",
    "class_names = list(class_labels.values())\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_names, zero_division=0)\n",
    "print(report[:2000])  # Print first 2000 characters to avoid too much output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Confusion Matrix (Sample Classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, class_names, sample_size=20):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix for a sample of classes.\n",
    "    \"\"\"\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Sample classes for visualization (too many classes to show all)\n",
    "    sample_indices = np.random.choice(len(class_names), min(sample_size, len(class_names)), replace=False)\n",
    "    sample_indices = sorted(sample_indices)\n",
    "    \n",
    "    # Extract submatrix\n",
    "    cm_sample = cm[np.ix_(sample_indices, sample_indices)]\n",
    "    sample_class_names = [class_names[i] for i in sample_indices]\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm_sample, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=sample_class_names, yticklabels=sample_class_names,\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.title(f'Confusion Matrix (Sample of {sample_size} Classes)', fontsize=14)\n",
    "    plt.xticks(rotation=90, ha='right', fontsize=8)\n",
    "    plt.yticks(rotation=0, fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(true_classes, predicted_classes, class_names, sample_size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(model, generator, class_labels, num_samples=12, correct_only=False):\n",
    "    \"\"\"\n",
    "    Visualize model predictions with confidence scores.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        generator: Data generator\n",
    "        class_labels: Dictionary mapping class indices to names\n",
    "        num_samples: Number of samples to display\n",
    "        correct_only: If True, show only correct predictions\n",
    "    \"\"\"\n",
    "    # Get a batch\n",
    "    generator.reset()\n",
    "    x_batch, y_batch = next(generator)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(x_batch, verbose=0)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(y_batch, axis=1)\n",
    "    \n",
    "    # Filter for correct/incorrect if needed\n",
    "    if correct_only:\n",
    "        indices = np.where(predicted_classes == true_classes)[0]\n",
    "    else:\n",
    "        indices = np.arange(len(predicted_classes))\n",
    "    \n",
    "    # Random sample\n",
    "    sample_indices = np.random.choice(indices, min(num_samples, len(indices)), replace=False)\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, sample_idx in enumerate(sample_indices):\n",
    "        img = x_batch[sample_idx]\n",
    "        true_label = class_labels[true_classes[sample_idx]]\n",
    "        pred_label = class_labels[predicted_classes[sample_idx]]\n",
    "        confidence = predictions[sample_idx][predicted_classes[sample_idx]]\n",
    "        \n",
    "        # Display image\n",
    "        axes[idx].imshow(img)\n",
    "        \n",
    "        # Color: green if correct, red if wrong\n",
    "        color = 'green' if true_classes[sample_idx] == predicted_classes[sample_idx] else 'red'\n",
    "        \n",
    "        title = f\"True: {true_label[:15]}\\nPred: {pred_label[:15]}\\nConf: {confidence:.2f}\"\n",
    "        axes[idx].set_title(title, fontsize=9, color=color)\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show predictions (mix of correct and incorrect)\n",
    "plot_predictions(best_model, test_generator, class_labels, num_samples=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7 Analyze Misclassifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_misclassifications(true_classes, predicted_classes, class_labels, top_n=10):\n",
    "    \"\"\"\n",
    "    Identify classes with highest misclassification rates.\n",
    "    \"\"\"\n",
    "    # Calculate per-class accuracy\n",
    "    class_accuracies = {}\n",
    "    \n",
    "    for class_idx in range(len(class_labels)):\n",
    "        class_mask = true_classes == class_idx\n",
    "        if np.sum(class_mask) > 0:\n",
    "            correct = np.sum(predicted_classes[class_mask] == class_idx)\n",
    "            total = np.sum(class_mask)\n",
    "            accuracy = correct / total\n",
    "            class_accuracies[class_labels[class_idx]] = accuracy\n",
    "    \n",
    "    # Sort by accuracy\n",
    "    sorted_accuracies = sorted(class_accuracies.items(), key=lambda x: x[1])\n",
    "    \n",
    "    # Display worst performing classes\n",
    "    print(f\"\\nTop {top_n} Worst Performing Classes:\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"{'Class Name':<40} {'Accuracy':<10}\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    for class_name, acc in sorted_accuracies[:top_n]:\n",
    "        print(f\"{class_name:<40} {acc:<10.2%}\")\n",
    "    \n",
    "    # Display best performing classes\n",
    "    print(f\"\\nTop {top_n} Best Performing Classes:\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"{'Class Name':<40} {'Accuracy':<10}\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    for class_name, acc in sorted_accuracies[-top_n:][::-1]:\n",
    "        print(f\"{class_name:<40} {acc:<10.2%}\")\n",
    "\n",
    "analyze_misclassifications(true_classes, predicted_classes, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Fine-tuning Transfer Learning Model (Advanced)\n",
    "\n",
    "After training with frozen base layers, we can fine-tune the model by unfreezing some layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new transfer learning model with some unfrozen layers\n",
    "fine_tune_model = create_transfer_learning_model('MobileNetV2', trainable_layers=20)\n",
    "\n",
    "# Load weights from previous training (optional)\n",
    "# fine_tune_model.load_weights('transfer_model_best.h5')\n",
    "\n",
    "# Compile with lower learning rate\n",
    "fine_tune_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.00001),  # Very low learning rate\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Fine-tuning model with unfrozen layers...\")\n",
    "print(f\"Total layers: {len(fine_tune_model.layers)}\")\n",
    "print(f\"Trainable layers: {sum([layer.trainable for layer in fine_tune_model.layers])}\")\n",
    "\n",
    "# Train for fewer epochs\n",
    "history_fine_tune = fine_tune_model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=get_callbacks('fine_tune_model', patience=5),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "fine_tune_test_acc, fine_tune_test_loss = evaluate_model(fine_tune_model, test_generator, 'Fine-tuned Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Save and Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "best_model.save('butterfly_classifier_final.h5')\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "# To load the model later:\n",
    "# loaded_model = keras.models.load_model('butterfly_classifier_final.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Prediction Function for New Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_butterfly(image_path, model, class_labels, top_k=5):\n",
    "    \"\"\"\n",
    "    Predict the species of a butterfly from an image file.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the image file\n",
    "        model: Trained model\n",
    "        class_labels: Dictionary mapping class indices to names\n",
    "        top_k: Number of top predictions to return\n",
    "    \"\"\"\n",
    "    # Load and preprocess image\n",
    "    img = load_img(image_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = img_array / 255.0\n",
    "    \n",
    "    # Make prediction\n",
    "    predictions = model.predict(img_array, verbose=0)[0]\n",
    "    \n",
    "    # Get top k predictions\n",
    "    top_indices = np.argsort(predictions)[-top_k:][::-1]\n",
    "    top_predictions = [(class_labels[idx], predictions[idx]) for idx in top_indices]\n",
    "    \n",
    "    # Display results\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Show image\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Input Image', fontsize=14)\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Show predictions\n",
    "    species = [pred[0][:20] for pred in top_predictions]\n",
    "    confidences = [pred[1] for pred in top_predictions]\n",
    "    \n",
    "    y_pos = np.arange(len(species))\n",
    "    ax2.barh(y_pos, confidences, color='steelblue')\n",
    "    ax2.set_yticks(y_pos)\n",
    "    ax2.set_yticklabels(species)\n",
    "    ax2.invert_yaxis()\n",
    "    ax2.set_xlabel('Confidence', fontsize=12)\n",
    "    ax2.set_title(f'Top {top_k} Predictions', fontsize=14)\n",
    "    ax2.set_xlim([0, 1])\n",
    "    \n",
    "    # Add confidence values\n",
    "    for i, v in enumerate(confidences):\n",
    "        ax2.text(v + 0.01, i, f'{v:.3f}', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return top_predictions\n",
    "\n",
    "# Example usage (uncomment and provide a valid image path):\n",
    "# predictions = predict_butterfly('path/to/butterfly/image.jpg', best_model, class_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
